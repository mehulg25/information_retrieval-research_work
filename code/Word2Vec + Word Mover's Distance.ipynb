{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Research Work/Docs/CISI.ALL\n",
      "CISI.ALL : 1460 items, over 108747 lines.\n",
      "../Research Work/Docs/CISI.BLN\n",
      "CISI.BLN : 0 items, over 86 lines.\n",
      "../Research Work/Docs/CISI.QRY\n",
      "CISI.QRY : 112 items, over 1525 lines.\n",
      "../Research Work/Docs/CISI.REL\n",
      "CISI.REL : 76 items, over 3114 lines.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "inputFolder = '../Research Work/Docs/' \n",
    "for root, directories, filenames in os.walk(inputFolder): \n",
    "    for filename in filenames: \n",
    "        print(os.path.join(root,filename))\n",
    "        with open(os.path.join(root, filename)) as f:\n",
    "            line_count = 0\n",
    "            id_set = set()\n",
    "            for l in f.readlines():\n",
    "                line_count += 1\n",
    "                if filename == \"CISI.REL\":\n",
    "                    id_set.add(l.lstrip(\" \").split(\" \")[0])\n",
    "                elif l.startswith(\".I \"):\n",
    "                    id_set.add(l.split(\" \")[1].strip())\n",
    "            print(f\"{filename} : {len(id_set)} items, over {line_count} lines.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".I 1\n",
      ".T 18 Editions of the Dewey Decimal Classifications\n",
      ".A Comaromi, J.P.\n",
      ".W The present study is a history of the DEWEY Decimal Classification.  The first edition of the DDC was published in 1876, the eighteenth edition in 1971, and future editions will continue to appear as needed.  In spite of the DDC's long and healthy life, however, its full story has never been told.  There have been biographies of Dewey that briefly describe his system, but this is the first attempt to provide a detailed history of the work that more than any other has spurred the growth of librarianship in this country and abroad.\n",
      ".X 1\t5\t1 92\t1\t1 262\t1\t1 556\t1\t1 1004\t1\t1 1024\t1\t1 1024\t1\t1\n"
     ]
    }
   ],
   "source": [
    "with open('../Research Work/Docs/CISI.ALL') as f:\n",
    "    lines = \"\"\n",
    "    for l in f.readlines():\n",
    "        lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
    "    lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
    "    \n",
    "# print n lines\n",
    "n = 5\n",
    "for l in lines[:n]:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents = 1460.\n",
      "\n",
      "Two Kinds of Power An Essay on Bibliographic Control Wilson, P. The relationships between the organization and control of writings and the organization and control of knowledge and information will inevitably enter our story, for writings contain, along with much else, a great deal of mankind's stock of knowledge and information.  Bibliographical control is a form of power, and if knowledge itself is a form of power, as the familiar slogan claims, bibliographical control is in a certain sense power over power, power to obtain the knowledge recorded in written form.  As writings are not simply, and not in any simple way, storehouses of knowledge, we cannot satisfactorily discuss bibliographical control as simply control over the knowledge and information contained in writings. \n"
     ]
    }
   ],
   "source": [
    "doc_set = {}\n",
    "doc_id = \"\"\n",
    "doc_text = \"\"\n",
    "for l in lines:\n",
    "    if l.startswith(\".I\"):\n",
    "        doc_id = l.split(\" \")[1].strip()\n",
    "    elif l.startswith(\".X\"):\n",
    "        doc_set[doc_id] = doc_text.lstrip(\" \")\n",
    "        doc_id = \"\"\n",
    "        doc_text = \"\"\n",
    "    else:\n",
    "        doc_text += l.strip()[3:] + \" \" # The first 3 characters of a line can be ignored.\n",
    "\n",
    "# Print something to see the dictionary structure, etc.\n",
    "print(f\"Number of documents = {len(doc_set)}\" + \".\\n\")\n",
    "print(doc_set[\"3\"]) # note that the dictionary indexes are strings, not numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of queries = 112.\n",
      "\n",
      "What is information science?  Give definitions where possible.\n"
     ]
    }
   ],
   "source": [
    "with open('../Research Work/Docs/CISI.QRY') as f:\n",
    "    lines = \"\"\n",
    "    for l in f.readlines():\n",
    "        lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
    "    lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
    "    \n",
    "qry_set = {}\n",
    "qry_id = \"\"\n",
    "for l in lines:\n",
    "    if l.startswith(\".I\"):\n",
    "        qry_id = l.split(\" \")[1].strip()\n",
    "    elif l.startswith(\".W\"):\n",
    "        qry_set[qry_id] = l.strip()[3:]\n",
    "        qry_id = \"\"\n",
    "        \n",
    "# Print something to see the dictionary structure, etc.\n",
    "print(f\"Number of queries = {len(qry_set)}\" + \".\\n\")\n",
    "print(qry_set[\"3\"]) # note that the dictionary indexes are strings, not numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     7    310\t0\t0.000000\n",
      "     7    320\t0\t0.000000\n",
      "     7    332\t0\t0.000000\n",
      "     7    375\t0\t0.000000\n",
      "     7    376\t0\t0.000000\n",
      "     7    645\t0\t0.000000\n",
      "     7    724\t0\t0.000000\n",
      "     7    725\t0\t0.000000\n",
      "\n",
      "Number of mappings = 76.\n",
      "\n",
      "['60', '85', '114', '123', '126', '131', '133', '136', '138', '140', '346', '359', '363', '372', '412', '445', '454', '461', '463', '469', '532', '537', '540', '553', '554', '555', '585', '590', '599', '640', '660', '664', '803', '901', '909', '911', '1027', '1053', '1169', '1179', '1181', '1190', '1191', '1326']\n"
     ]
    }
   ],
   "source": [
    "rel_set = {}\n",
    "with open('../Research Work/Docs/CISI.REL') as f:\n",
    "    for l in f.readlines():\n",
    "        qry_id = l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[0]\n",
    "        doc_id = l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[-1]\n",
    "        if qry_id in rel_set:\n",
    "            rel_set[qry_id].append(doc_id)\n",
    "        else:\n",
    "            rel_set[qry_id] = []\n",
    "            rel_set[qry_id].append(doc_id)\n",
    "        if qry_id == \"7\":\n",
    "            print(l.strip(\"\\n\"))\n",
    "    \n",
    "# Print something to see the dictionary structure, etc.\n",
    "print(f\"\\nNumber of mappings = {len(rel_set)}\" + \".\\n\")\n",
    "print(rel_set[\"3\"]) # note that the dictionary indexes are strings, not numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[]\n",
    "list1 = list(doc_set.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qry_set\n",
    "queries = list(qry_set.values())\n",
    "\n",
    "len(qry_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1572"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = list1+queries\n",
    "len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def convert_lower_case(data):\n",
    "    return np.char.lower(data)\n",
    "\n",
    "def remove_stop_words(data):\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if w not in stop_words and len(w) > 1:\n",
    "            new_text = new_text + \" \" + w\n",
    "    return new_text\n",
    "\n",
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data\n",
    "\n",
    "def remove_apostrophe(data):\n",
    "    return np.char.replace(data, \"'\", \"\")\n",
    "\n",
    "def lemma(data):\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        new_text = new_text + \" \" + lemmatizer.lemmatize(w)\n",
    "    return new_text\n",
    "\n",
    "def preprocess(data):\n",
    "    data = convert_lower_case(data)\n",
    "    data = remove_punctuation(data) #remove comma seperately\n",
    "    data = remove_apostrophe(data)\n",
    "    data = remove_stop_words(data)\n",
    "    data = lemma(data)\n",
    "    data = remove_punctuation(data)\n",
    "    data = lemma(data) #needed again as we need to stem the words\n",
    "    data = remove_punctuation(data) #needed again as num2word is giving few hypens and commas fourty-one\n",
    "    data = remove_stop_words(data) #needed again as num2word is giving stop words 101 - one hundred and one\n",
    "    #data = word_tokenize(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(list1):\n",
    "\ttokenized= []\n",
    "\ttokenized.append(preprocess(sentence))\n",
    "\tlist1[i] = tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list1)):\n",
    "    for sentence in list1[i]:\n",
    "        tokenized= []\n",
    "        tokenized.append(word_tokenize(sentence))\n",
    "        list1[i] = tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for sublist in list1:\n",
    "    for item in sublist:\n",
    "        output.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(output, size=100, window=10, min_count=1, workers=15, sg=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.similarities import WmdSimilarity\n",
    "num_best = 1460\n",
    "instance = WmdSimilarity(output, model, num_best=1460)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 'What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?', '2': 'How can actually pertinent data, as opposed to references or entire articles themselves, be retrieved automatically in response to information requests?', '3': 'What is information science?  Give definitions where possible.', '4': 'Image recognition and any other methods of automatically transforming printed text into computer-ready form.', '5': 'What special training will ordinary researchers and businessmen need for proper information management and unobstructed use of information retrieval systems? What problems are they likely to encounter?', '6': 'What possibilities are there for verbal communication between computers and humans, that is, communication via the spoken word?', '7': 'Describe presently working and planned systems for publishing and printing original papers by computer, and then saving the byproduct, articles coded in data-processing form, for further use in retrieval.', '8': 'Describe information retrieval and indexing in other languages. What bearing does it have on the science in general?', '9': 'What possibilities are there for automatic grammatical and contextual analysis of articles for inclusion in an information retrieval system?', '10': 'The use of abstract mathematics in information retrieval, e.g. group theory.', '11': 'What is the need for information consolidation, evaluation, and retrieval in scientific research?', '12': 'Give methods for high speed publication, printing, and distribution of scientific journals.', '13': 'What criteria have been developed for the objective evaluation of information retrieval and dissemination systems?', '14': 'What future is there for automatic medical diagnosis?', '15': 'How much do information retrieval and dissemination systems, as well as automated libraries, cost? Are they worth it to the researcher and to industry?', '16': 'What systems incorporate multiprogramming or remote stations in information retrieval?  What will be the extent of their use in the future?', '17': 'Means of obtaining large volume, high speed, customer usable information retrieval output.', '18': 'What methods are there for encoding, automatically matching, and automatically drawing structures extended in two dimensions, like the structural formulas for chemical compounds?', '19': 'Techniques of machine matching and machine searching systems. Coding and matching methods.', '20': 'Testing automated information systems.', '21': 'The need to provide personnel for the information field.', '22': 'Automated information in the medical field.', '23': 'Amount of use of books in libraries. Relation to need for automated information systems .', '24': 'Educational and training requirements for personnel in the information field. Possibilities for this training.  Needs for programs providing this training.', '25': 'International systems for exchange and dissemination of information.', '26': 'Cost and determination of cost associated with systems of automated information.', '27': 'Computerized information retrieval systems.  Computerized indexing systems.', '28': 'Computerized information systems in fields related to chemistry.', '29': 'Specific advantages of computerized index systems.', '30': 'Information dissemination by journals and periodicals.', '31': 'Information systems in the physical sciences.', '32': 'Attempts at computerized and mechanized systems for general libraries. Problems and methods of automated general author and title indexing systems.', '33': 'Retrieval systems which provide for the automated transmission of information to the user from a distance.', '34': 'Methods of coding used in computerized index systems.', '35': 'Government supported agencies and projects dealing with information dissemination.', '36': 'What are some of the theories and practices in computer translating of texts from one national language to another?  How can machine translating compete with traditional methods of translating in comprehending nuances of meaning in languages of different structures?', '37': 'What lists of words useful for indexing or classifying material are available?  Wanted are lists of terms that are descriptive vocabularies of particular fields or schedules of words that are related to each other in meaningful schemes.  Wanted are lists that have been tested, at least to some extent, and found useful for organizing material and for retrieving it.', '38': 'How can access words in an information retrieval system be kept up to date? Word meanings and usage often change and lists must be dynamic to be current. What definitions of the problem and progress toward solutions have been made in providing necessary flexibility in systems of subject headings, index words, or other symbols used for getting at stored data?', '39': 'The progress of information retrieval presents problems of maladjustment and dislocation of personnel.  Training and retraining of people to use the new equipment is important at all levels.  Librarians, assistants, technicians, students, researchers, and even executives will need education to learn the purpose, values, and uses of information systems and hardware. What programs have been developed to change the attitudes and skills of traditional workers and help them to learn the newer techniques?', '40': 'What is the status of machine translation?  What progress has been made in the use of computers to transfer from one language to another with some degree of automation?  What problems and stumbling blocks have been found and are they considered to be insurmountable limitations or only challenging to the field of documentation on an international scale?', '41': 'Is alphabetical ordering of material considered to be a useful tool in information retrieval?  What studies have been done to compare the effectiveness of alphabetical order with other organization schemes? Is there a generally accepted form of arranging material in alphabetical order, and is there an easy way of achieving this form without going to a great amount of effort?', '42': 'The average student or researcher has difficulty in comprehending the vocabulary of information retrieval.  It appears important that this new field be understood before it is to be fully accepted.  What basic articles would provide an understanding of the various important aspects of the information storage and retrieval?', '43': 'The difficulties encountered in information retrieval systems are often less related to the equipment used than to the failure to plan adequately for document analysis, indexing, and machine coding.  The position of the programmer is to take a problem and write it in a way in which the equipment will understand.  What articles have been written describing research in maximizing the effectiveness of programming?', '44': 'There are presently fifty to one hundred technical journals being published.  On the average, two new journals appear every day.  In the many journals published, one to two million articles appear every year.  What attempts have been made to cope with this amount of scientific and technical publication in terms of analysis, control, storage, and retrieval?', '45': 'I am looking for information about the impact of automation on libraries and its significance for libraries in general.  This includes the increasing importance of automation in view of the proliferation of information today, and how automation can help libraries cope with this problem.  How will automation affect libraries and how should they react to the idea of automation?', '46': 'I am seeking information on the use of data processing in libraries and the mechanization of routine library processes and procedures.  I would like descriptions of both general and specific applications of automation in such areas as circulation, cataloging, acquisitions, serial records, and other record-keeping.  Examples should be based on the operation of a conventional public or university library, or practices in a special library which could also be applied in a public or university library.  Give descriptions of equipment and operations, both present and projected.', '47': 'Is there any established means at present for an international exchange of material about information retrieval?  If there is, does it take the form of an international agency or center which regularly distributes information retrieval methods and research results?  If there is not, in what ways has this material crossed national boundaries?  What seem to have been some of the problems blocking a better international exchange, and is any effort being made to solve some of those problems?', '48': 'Information retrieval is still such a new and experimental field that a line distinguishing research and practice is often difficult - even impossible - to draw.  Are there, however, actual centers of research on information retrieval?  If so, in which countries are they located?  Who supports them - government, business, universities, or libraries?  Can information retrieval as a specialized research discipline be said to be emerging, or is it still an amalgam of skills from other fields, such as mathematics, engineering, and library science?  In other words, tell me about information retrieval research.', '49': 'Most resources have been spent on applying information retrieval techniques to the physical and medical sciences.  But, has information retrieval been used at all in the natural sciences, social sciences, and humanities?  If so, what have been some of the problems which have been encountered with these subject areas and how have they been solved, if at all?  Have the characteristics of these subject areas necessitated the development of new information retrieval techniques? What are the prospcts for future machine control in these areas?', '50': 'Is there any use for traditional classification schemes - DDC, UDC, LC, etc. - in information retrieval systems?  If there is, which scheme appears most suited to machine use and where has it been applied? If there is not, why are these classification schemes irrelevant? Has research shown that a subject classification of knowledge is completely unnecessary in machine systems? Or, have new schemes been devised which appear to be more suited to machine use?', '51': 'Coordinate indexing utilizes descriptors for controlled language.  Of what use are descriptors in the construction of an index?  How can descriptors be used for searching in an information retrieval system?', '52': 'What are the characteristics of MEDLARS (Medical Literature Analysis and Retrieval System) project which has been undertaken by the National Library of Medicine?  How does it index current medical journals and of what relation is this indexing system to Index Medicus? What are the major components of the MEDLARS project and its major operating details?', '53': 'How can the computer be used in medical science for diagnostic and clinical record keeping purposes?  Have any programs of automation been tried in hospitals?  If so, what have been the results? What problems have been encountered in the use of automation in medicine?  For what purposes can an automated system of clinical records be used?  What are other possible uses of the computer in medicine?', '54': 'What is the effect on librarians of automation?  Note the new types of technology to be used in the library which will have an effect on the status, position, and function of the librarians.  What changes are being contemplated or have been initiated to introduce automation into the education of librarians?', '55': 'What are the aims and objectives of the medical literature analysis and retrieval system (MEDLARS)?  How does MEDLARS operate?  What are the possible applications of MEDLARS to future information retrieval systems?', '56': \"The standard method of finding information in today's libraries is through the use of the alphabetically arranged card catalog or the classified catalog based on a classification system such as the DC or LC.  Can these systems be modified for use with automated information retrieval?\", '57': 'In catalogs which are either arranged alphabetically or arranged by classification number, the LC entry, printed in readable language, is ultimately important because the individual looking for information has a definite author, title, or subject phrase in his language (probably English in our case) in mind.  Will LC entries and subject headings be used in the same manner in automated systems?', '58': 'Bibliographic control before and after MARC is reviewed.  The capability of keying into online systems brought an interdependence among libraries, the service centers that mediate between them, and the large utilities that process and distribute data.  From this has developed the basic network structure among libraries in the United States.  The independent development of major networks has brought problems in standardization and coordination. The authors point out that while technology has led toward centralization of automated library services, new developments are now pushing toward decentralization.  Coordination is a requirement to avoid fragmentation in this new environment.', '59': 'The retrieval performance of book indexes can be measured in terms of their ability to direct a user selectively to text material whose identity but not location is known.  The method requires human searchers to base their searching strategies on actual passages from the book rather than on test queries, natural or contrived.  It circumvents the need for relevance judgement, but still yields performance indicators that correspond approximately to the recall and precision ratios of large document retrieval system evaluation.  A preliminary application of the method to the subject indexing of two major encyclopedias showed one encyclopedia apparently superior in both the finding and discrimination abilities of retrieval performance.  The method is presently best suited for comparative testing since its ability to yield absolute or reproducible measures is as yet not established.', '60': \"A linkage similarity measure which takes into account both the bibliographic coupling of documents and their cocitations (both cited and citing papers) produced improved document retrieval over a measure based only on bibliographic coupling.  The test collection consisted of 1712 papers whose relevance to specific queries had been judged by users.  To evaluate the effect of using cocitation data, we calculated for each query two measures of similarity between each relevant paper and every other paper retrieved. Papers were then sorted by the similarity measures, producing two ordered lists.  We then compared the resulting predictions of relevance, partial relevance, and non-relevance to the user's evaluations of the same papers. Overall, the change from the bibliographic coupling measure to the linkage similarity measure, representing the introduction of cocitation data, resulted in better retrieval performance.\", '61': 'The way that individuals construct and modify search queries on a large interactive document retrieval system is subject to systematic biases similar to those that have been demonstrated in experiments on judgements under uncertainty.  These biases are shared by both naive and sophisticated subjects and cause the inquirer searching for documents on a large interactive system to construct and modify queries inefficiently.  A searching algorithm is suggested that helps the inquirer to avoid the effect of these biases.', '62': 'This article concerns the problem of how to permit a patron to represent the relative importance of various index terms in a Boolean request while retaining the desirable properties of a Boolean system. The character of classical Boolean systems is reviewed and related to the notion of fuzzy sets.  The fuzzy set concept then forms the basis of the concept of a fuzzy request in which weights are assigned to index terms. Ther properties of such a system are discussed, and it is shown that such systems retain the manipulability of traditional Boolean requests.', '63': 'A commercially available online search was used as a standard for comparative searching and evaluation of an in-house information system based on automatic indexing.  System features were identified and evaluated on the basis of their usefulness in various kinds of searching, their ease in implementation, and how they are influenced by differences in user type or specific applications.  Some common features of the commercial system, such as online instruction, user-specified print formats, dictionary display, and truncation, are seen to be unnecessary or impractical for the in-house system.  In designing the in-house system, therefore, detald consideration must be given to the applications, operating environment, and real user needs.  While a commercial system can serve as a useful standard for comparative evaluation, one must be careful not to attempt to duplicate it blindly in-house.', '64': 'It is argued that in information science we have to distinguish physical, objective, or document space from perspective, subjective, or information space.  These two spaces are like maps and landscapes: each is a systematic distortion of the other.  However, transformation can be easily made once the two spaces are distinguished.  If the transformations are omitted we only get unhelpful physical solutions to information problems.', '65': 'The use of document clusters has been suggested as an efficient file organization for a document retrieval system.  It is possible that by using this information about the relationships between documents that the effectiveness of the system (i.e., its ability to distinguish relevant from non-relevant documents) may also be improved.  In this paper a probabilistic model of cluster searching  based on query classification is described.  This model is tested with retrieval experiments which indicate that it can be more effective than heuristic cluster searches and cluster searches based on other models.  It can also be more effective than a full search in which every document is compared to the query.  The efficiency aspects of the implementation of the model are discussed.', '66': 'Current online library network technology is described, including the physical and functional aspects of networks.  Three types of networks are distinguished:  search service (e.g., SDC, Lockheed), customized service that provide bibliographic files (e.g., OCLC, Inc., RLIN), and service center (e.g., NELINET, INCOLSA).  It is predicted that as technology evolves more services will be provided outside the library directly to the user through his home or office.', '67': 'An experimental computer program has been developed to classify documents according to the 80 sections and five major section groupings of Chemical Abstracts (CA).  The program uses pattern recognition techniques supplemented by heuristics.  During the \"training\" phase, words from pre-classified documents are selected, and the probability of occurrence of each word in each section of CA is computed and stored in a reference dictionary.  The \"classification\" phase matches each word of a document title against the dictionary and assigns a section number to the document using weights derived from the probabilities in the dictionary.  Heuristic techniques are used to normalize word variants such as plurals, past tenses, and gerunds in both the training phase and the classification phase.  The dictionary lookup technique is supplemented by the analysis of chemical nomenclature terms into their component word roots to influence the section to which the documents are assigned.  Program performance and human consistency have been evaluated by comparing the program results against the published sections of CA and by conducting an experiment with people experienced in the assignment of documents to CA sections.  The program assigned approximately 78% of the documents to the correct major section groupings of CA and 67% of the correct sections or cross-references at a rate of 100 documents per second.', '68': 'Some of the automatic classification procedures used in information retrieval derive clusters of documents from an intermediate similarity matrix, the computation of which involves comparing each of the documents in the collection with all of the others.  It has recently been suggested that many of these comparisons, specifically those between documents having no terms in common, may be avoided by means of the uyse of an inverted file to the document collection.  This communication shows that the approach will effect reductions in the number of interdocument comparisons only if the documents are each indexed by a limited number of indexing terms; if exhaustive indexing is used, many document pairs will be compared several times over and the computation will be greater than when conventional approaches are used to generate the similarity matrix.', '69': 'The Use of a minicomputer in various phases of creating the thesaurus for the National Information Center for Special Education Materials (NICSEM) database is described.  The minicomputer is used to collect, edit, and correct candidate thesaurus terms.  The use of the minicomputer eases the process of grouping terms into files of similar concepts and facilitates the generation of products useful in vocabulary review and in term structuring.  Syndetic relations, indicated by assigning coded identification numbers, are altered easily in the design phase to reflect restructuring requirements.  Because thesaurus terms are already in machine- readable form, it is simple to prepare print programs to provide permuted, alphabetic, hierarchical, and chart formatted term displays.  Overall, the use of the minicomputer facilitates initial thesaurus entry development by reducing clerical effort, editorial staff decisions, and overall processing times.', '70': 'Decision Support Systems (DSS) represent a concept of the role of computers within the decision making process.  The term has become a rallying cry for researchers, practitioners, and managers concerned that Management Science and Management Information Systems fields have become unnecessarily narrow in focus.  As with many rallying cries, the term is not well defined.  For some writers, DSS simply mean interactive systems for use by managers.  To others, the key issue is support, rather than system.  They focus on understanding and improving the decision process; a DSS is then designed using any available and suitable technology. Some researchers view DSS as a subfield of MIS, while others regard it as an extension of Management Science techniques.  The former define Decision Support as providing managers with access to data and the latter as giving them access to analytic models.  The key argument of this paper is that the term DSS is relevant to situations where a \"final\" system can be developed only through an adaptive process of learning and evolution.  The design strategy must then focus on getting finished; this is very different from Management Science and Data Processing approaches.  The research issued for DSS center around adaption and evolution; they include managerial learning representation of tasks and user behavior, design architecture and strategies for getting started.', '71': 'A new method is described to extract significant phrases in the title and the abstreact of scientific or technical documents.  The method is based upon a text structure analysis and uses a relatively small dictionary. The dictionary has been constructed based on the knowledge about concepts in the field of science or technology and some lexical knowledge.  For significant phrases and their component items may be used in different meanings among the fields.  A text analysius approach has been applied to select significant phrases as substantial and semantic information carriers of the contents of the abstract.  The results of the experiment for five sets of documents have shown that the significant phrases are effectively extracted in all cases, and the number of them for every document and the processing time is fairly satisfactory.  The information representation of the document, partly using the method, is discussed with relation to the construction of the document information retrieval system.', '72': 'Passage retrieval (already operational for lawyers) has advantages in output form opver references retrieval and is economically feasible. Previous experiments in passage retrieval for scientists have demonstrated recall and false retrieval rates as good or better than those of present reference retrieval services.  The present experiment involved a greater variety of forms of retrieval question.  In addition, search words were selected independently by two different people for each retrieval question. The search words selected, in combination with the computer procedures used for passage retrieval, produced average recall ratios of 72 and 67%, respectively, for the two selectors.  The false retrieval rates were (except for one predictably difficult question) respectively 13 and 10 falsely retrieved sentences per answer-paper retrieved.', '73': 'In this paper we describe a practical method of partial-match retrieval in very large data files.  A binary code word, called a descriptor, is associated with each record of the file.  These record descriptors are then used to form a derived descriptor for a block of several records, which will serve as an index for the block as a whole; hence, the name \"indexed descriptor files.\"  First the structure of these files is described and a simple, efficient retrieval algorithm is presented.  Then its expected behavior, in terms of storage accesses, is analyzed in detail.  Two different file creation procedures are sketched, and a number of ways in which the file organization can be \"tuned\" to a particular application is suggested.', '74': 'Recenty technological advances and the success of OCLC, Inc. has led to the emergence of three additional nonprofit library networks:  the Research Libraries Information Network (RLIN) of the Research Libraries Group, Inc., the University of Toronto Library Automation System (UTLAS), and the Washington Library Network (WLN).  This paper examines the economic and technological factors affecting the evolution of these networks and also explores the role of those state and regional (multistate) networks that broker OCLC services.  The competitive and cooperative nature of network relationships is a major theme of the discussion.', '75': 'A new type of natural language parser is presented.  The idea behind this parser is to map input sentences into the deepest form of the representation of their meaning and inferences, as is appropriate.  The parser is not distinct from an entire understanding system.  It uses an integrated conception of inferences, scripts, plans and other knowledge to aid in the parse.  Furthermore, it does not attempt to parse everything it sees.  Rather, it determines what is most interesting and concentrates on that, ignoring the rest.', '76': 'This paper discusses the origins of library networks and traces their development in the United States in the late 1960s through the present. The concept of resource sharing, with particular attention to the inter- library loan and programs for the cooperative acquisition and storage of materials, is examined in relationship to library networks.  In particular, attention is given to the question of how these two major components of library cooperation, which have tended to be separate, might become more closely integrated.', '77': 'This paper presents a method of normalizations of English titles and their retrieval.  The title expressed by a noun phrase or a noun clause is converted to a function-expression by parsing.  For the retrieval with a reasonable recall rate as well as a high precision rate, the function- expression is transformed to a predicate-governor form, and then normalized to a standard form.  Therefrom, various items are extracted and recorded in a hierarchical tree-like inverted file.  In order to keep the recall rate in a reasonable value, several retrieval stages are implemented based on the key-term and case-label matching.  The retrieval is controlled by the preciseness of the specification of case-labels for each key-term.', '78': \"A generalization of the notion of ATN grammar, called a cascaded ATN (CATN), is prescribed.  CATN's permit a decomposition of complex language understanding behavior into a sequence of cooperating ATN's with separate domain of responsibility, where each stage (called an ATN transducer) takes its input from the output of the previous stage.  The paper includes an extensive discjussion of the principles of factoring-conceptual factoring reduces the number of places that a given fact needs to be represented in a grammar, and hypothesis factoring reduces the number of distinct hypotheses that have to be considered during parsing.\", '79': 'Algorithms are given to process partially specified queries in a compressed database system.  The proposed methods handle effectively queries that use either whole words or word fragments as language elements. The methods are compared and critically evaluated in terms of the design and retrieval costs.  The analyses show that the method which exploits the interdependence of fragments as well as the relevance of fragments to records in the file has maximum design cost and least retrieval cost.', '80': \"From the detailed analysis of eight previously published mathematical models, a general formulation of Bradford's distribution can be deduced as follows:  y = a log(x + c) + b, where y is the ratio of the cumulative frequency of articles to the total number of articles and x is the ratio of the rank of journals to the total number of journals.  The parameters a, b, and c are the slope, the intercept, and the shift in a straight line to log rank, respectively.  Each of the eight models is a special case of the general formulation and is one of five types of formulation.  In order to estimate three unknown parameters, a statistical method using root-weighted square error is proposed.  A comparative experiment using 11 databases suggests that the fifth type of formulation with three unknown parameters is the best fit to the observed data.  A further experiment shows that the deletion of the droop data leads to a more accurate value of parameters and less error.\", '81': 'The lexical problems in large information systems are created by the necessity of handling a great number of names and their interrelations. Such lexical problems are not covered completely by the concept data dictionaries, which are mostly concerned with database scheme design rather than the execution of operations.  In this paper we introduce our view of a lexical subsystem as a separate component in an information system architecture, to deal with linguistic and control functions concerning the lexical problems in local and network environments.  The lexical suybsystem is a special efficiently organized program package, which plays the role of a \"linguistic filter\" in a broad sense for lexically incorrect queries, promotes integration of databases and information retrieval systems, and facilitates the creation of local information systems.  We hope that lexical subsystems can become productive for any large, especially distributed, information system.', '82': 'The relational model has received increasing attention during the past decade.  Its advantages include simplicity, consistency, and a sound theoretical basis.  In this article, the naturalness of viewing information retrieval relationally is demonstrated.  The relational model is presented, and the relational organization of a bibliographical database is shown. The notion of normalization is introduced and first, second, third, and fourth normal forms are demonstrated.  Relational languages are discussed, including the relational calculus, relational algebra, and SEQUEL. Numerous examples pertinent to information retrieval are presented in these relational languages.  Advantages of the relational approach to information retrieval are noted.', '83': 'This paper describes an architectural approach that provides information exchange across a broad spectrum of user applications and office automation offerings.  Some of the architectures described herein are currently implemented in existing IBM products.  These and other architectures will provide the basis for document interchange capability between products such as the IBM 5520 Administrative System, the IBM System/370 Distributed Office Support System (DISOSS), and the IBM Displaywriter System. Specifically described is a document distribution architecture and its associated data streams and others.  A general overview of the architectures as opposed to a detailed technical description is provided.  The architectures described are protocols for interchange between application processes; they do not address the specific user interface.  The document distribution architectures utilize SNA for data transmission and communications control facilities.', '84': \"A technique is described for automatic reformulation of boolean queries.  Based on patron relevance judgements of an initial retrieval, prevalence measures are derived for terms appearing in the retrieved set of documents that reflect a term's distribution among the relevant and non-relevant documents.  These measures are then used to guide the construction of a boolean query for a subsequent retrieval.  To illustrate the technique, a series of tests is described of its application to a small data base in an experimental environment.  Results compare favourably with feedback as employed in a SMART-type system.  MOre extensive testing is suggested to validate the technique.\", '85': 'This paper is intended to propose a new methodological approach to the conception and development of natural language understanding systems. This new contribution is supported by the design, implementation, and experimentation of DONAU:  a general purpose domain oriented natural language understanding system developed and presently running at the Milan Polytechnic Artificial Intelligence Project.  The system is based on a two level modular architecture intended to overcome the lack of flexibility and generality often pointed out in many existing systems, and to facilitate the exchange of results and actual experiences between different projects. The horizontal level allows an independent and parallel development of the single segments of the system (syntactic analyser, information extractor, legality controller).  The vertical level ensures the possibility of changing (enlarging or redefining) the definition of the semantic domain on which each particular version of the system is oriented and specialized in a simple, incremental, and user-oriented way.  In the paper the general architecture of the system and the mode of operation of each segment are illustrated in detail.  Linguistic models, knowledge representation, and parsing algorithms are described and illustrated by means of selected examples.  Performance evaluations of the system in the application version on data base inquiry are reported and discussed.  Promising directions for future research are presented in the conclusions.', '86': 'Approximate matching of strings is reviewed with the aim of surveying techniques suitable for finding an item in a database when there may be a spelling mistake or other error in the keyword.  The methods found are classified as either equivalence or similarity problems. Equivalence problems are seen to be readily solved using canonical forms. For similarity problems difference measures are surveyed, with a full description of the well-established dynamic programming method relating this to the approach using probabilities and likelihoods.  Searches for approximate matches in large sets using a difference function are seen to be an open problem still, though several promising ideas have been suggested.  Approximate matching (error correction) during parsing is briefly reviewed.', '87': 'A prototype system is created that integrates a microfiche catalog into an online computer system for bibliographic control.  Costs and operational data are collected and analyzed.  The system permits the more economical microfiche storage of catalog records than would be feasible for comparable online magnetic disk storage.  Experimental tests demonstrate the feasibility of the online microfiche catalog system for use in library technical services and retrieval of bibliographic data.  The primary result of the project is the creation of a completely operational facility, including all equipment, software, procedures, and data bases necessary to demonstrate the system.  A second set of results is derived from the experimental use of the system and the evaluation of costs and times for various operations.  The cost effectiveness of the online microfiche catalog is demonstrated.', '88': 'The question is asked whether it is feasible to use subsets of natural languages as query languages for data bases in actual applications using the question answering system \"USER SPECIALTY LANGUAGES\" (USL). Methods of evaluating a natural language based information system will be discussed.  The results (error and language structure evaluation) suggest how to form the general architecture of application systems which use a subset of German as query language.', '89': \"In 1978 Collier presented some hypothetical data on economic aspects of the use of online services as compared with subscriptions to printed services in libraries.  Collier's view of the economics of online searching seems misleadingly pessimistic because:  1.  It looks only at costs but not at effectiveness in comparing the two modes of access and searching.  An analysis combining cost and effectiveness aspects (i.e., a cost-effectiveness analysis) would give a completely different picture.  2.  The way the cost data are presented is grossly unfair to the online mode of access and use.  This work contains corrected information regarding online and printed services in libraries.\", '90': \"Many information scientists are concerned with the operation of document retrieval systems serving scientists in various fields.  The scientists served by these systems are often members of what have been called invisible colleges, groups of scientists in frequent communication with one another and involved with highly specialized subject matters.  Often such groups are considered to share an intellectual perspective regarding this subject matter, which is sometimes referred to as a paradigm.  The purpose of this paper is to show how it is possible to identify paradigms, using the techniques of citation analysis.  I will operationalize the notion of paradigm as a 'consensual structure of concepts in a field.' Suppose we have obtained a set of papers pertaining to some topic.  Already knowing something about the field, we read each text and mark passages in which certain specific concepts are used or discussed.  For example, we might find that a concept designated 'A' appears in some sub-set of the papers.  Suppose further that we identify those papers in which concepts 'A' and 'B' are used together in the same papers in a certain specified manner. Clearly not all concepts will combine in a natural way, and not all authors combining concepts 'A' and 'B' will do so in the same way, though some predominant mode may emerge.  For a set of n concepts their structure is given by the totality of admissible combinations of concepts taken from two to n at a time.  The frequency with which a given combination occurs in the sample of papers on the topic is a measure of the degree of consensus regarding the particular concept combination within the corpus.  For concepts taken two at a time, the structure can be displayed as a graph with concepts as nodes and the relations between them represented as lines (arcs) connecting the nodes.  This definition of concept structure is similar to the semantic network of artificial intelligence except that in our approach a measure of consensus weights each arc of the graph.\", '91': 'One mode of online retrieval in Scisearch or Social Scisearch involves entering pairs of authors\\' names believed to be jointly cited by subsequent writers and retrieving papers in which cocitations occur.  Six pairs were formed with the names of four authors prominent in the social indicators movement (Bauer, Duncan, Land, and Sheldon).  Documents by the four were not specified.  It was thought that the pair Duncan and Land would retrieve papers in which indicator-type data would be integrated with path-analytic causal modeling.  All other pairs seemed likely to retrieve a \"general social indicators\" literature.  The 298 retrieved papers confirmed expectattions.  It was found that 121 papers generally cited social indicators (SI) documents by the input authors and frequently had SI language in their titles.  Other signs of content also identified them as papers of the SI movement.  The 177 papers retrieved on Duncan and Land generally cited causal modeling documents by the input pair and were path-analytic in nature.  As expected, they were relatively \"harder\" than the first group of papers, although the two groups are akin and are formally linked through citations in certain papers.  An additional result is that papers citing at least three of the input authors tend to be overviews of the SI movement.', '92': 'The number of databases, records contained in databases and the online use of databases has increased dramatically over the past several years, bringing the 1979 totals for bibliographic, bioliographic-related, and natural language databases to 528.  These 528 databases contain 148 million records.  Some 4 million online searches were conducted via the major U.S. and Canadian systems in 1979.', '93': 'A method of iterative searching, using the results of one iteration search to formulate the next iteration search, was applied to a full-text database consisting of some 2400 documents and 1,3000,000 text-words of Hebrew and Aramaic.  The iterative method consists of clustering the documents returned in an iteration, using weighting by proximity and by frequency simultaneously. The process produces searchonyms, which are terms synonymous to keywords in the context of a single query.  Augumenting or replacing keywords by searchonyms via manual or automatic feedback leads to the formulation of the next iteration search.  The results of the experiment are consistent with those of an earlier small-scale experiment on an English database, and indicate that in contrast to global clustering where the size of matrices limits applications to small databases and improvements are doubtful, local metrical methods appear to be well suited to arbitrarily large databases, improving precision and recall simultaneously.  Further experiments using more test-queries run on even larger databases should be made to collect further evidence as to the performance of these methods.', '94': 'REFLES is a microcomputer-based system for data retrieval in library environments.  The problem of information retrieval is discussed from a theoretical point of view, followed by an analysis of the reference process and data thereby gathered, leading to a description of REFLES in terms of its hardware and software.  REFLES, a prototype system at present, currently functions in a test environment.  Examples of data contained in the system and of its use are presented.  Future considerations and speculations on other versions of the system conclude the paper.', '95': 'A major deficiency of traditional Boolean systems is their inability to represent the varying degrees to which a document may be written on a subject. In this article we isolate a number of criteria that should be met by any Boolean system generalized to have a weighting capability.  It is proven that only one weighting rule satisfies these conditions--that associated with fuzzy- set theory--and that this weighting scheme satisfies most of the other properties associated with Boolean algebra as well.  Probabilistic weighting is then introduced as an alternative approach and the two systems compared. In the limit of zero/one weights, all systems considered converge to traditional Boolean retrieval.', '96': 'Several papers have appeared that have analyzed recent developments in the problem of processing, in a document retrieval system, queries expressed as Boolean expressions.  The purpose of this paper is to continue that analysis. We shall show that the concept of threshold values resolves the problems inherent with relevance weights.  Moreover, we shall explore possible evaluation mechanisms for retrieval of documents, based on fuzzy-set-theoretic considerations.', '97': 'There has been a good deal of work on information retrieval systems that have continuous weights assigned to the index terms that describe the records in the database, and/or to the query terms that describe the user queries. Recent articles have analyzed retrieval systems with continuous weights of either type and/or with a Boolean structure for the queries.  They have also suggested criteria which such systems ought to satisfy and record evaluation mechanisms which partially satisfy these criteria.  We offer a more careful analysis, based on a generalization of the discrete weights.  We also look at the weights from an entirely different approach involving thresholds, and we generate an improved evaluation mechanism which seems to fulfill a larger subset of the desired criteria than previous mechanisms.  This new mechanism allows the user to attach a \"threshold\" to the query term.', '98': 'Online retrieval systems may be difficult to use, especially by end users, because of heterogeneity and complexity.  Investigations have concerned the concept of a translating computer interface as a means to simplify access to, and operation of, heterogeneous bibliographic retrieval systems and databases.  The interface allows users to make requests in a common language. These requests are translated by the interface into the appropriate commands for whatever system is being interrogated.  System responses may also be transformed by the interface into a common form before being given to the users.  Thus, the network of different systems is made to look like a single \"virtual\" system to the user.  The interface also provides instruction and other search aids for the user.  The philosophy, design, and implementation of an experimental interface named CONIT are described.', '99': 'The evaluation of the concept of a translating compuyter interface for simplifying operation of multiple, heterogenous online bibliographic retrieval systems has been undertaken.  An experimental retrieval system, named CONIT, was built and tested under controlled conditions with inexperienced end users.  A detailed analysis of the experimental usages showed that users were able to master interface operation sufficiently well to find relevant document references.  Success was attributed, in part, to a simple command language, adequate online instruction, and a simplified natural-language, keyword/stem approach to searching.  It is concluded that operational interfaces of the type studied can provide for increased usability of existing system in a cost effective manner, especially for searchers. Furthermore, more advanced interfaces based on improved instruction and automated search strategy techniques could further enhance retrieval effectiveness for a wide class of users.', '100': 'This paper notes the benefits accruing from interaction between computerized retrieval systems and micrographic retrieval systems.  It reviews current state of automated micrographic retrieval technology.  The conclusion is that with a combination of advances in communications technology, and sophisticated indexing input from libraries and information scientists, the new generation of automated micrographs devices may constitute the on-line document retrieval systems of the future.', '101': 'Conventional information retrieval processes are largely based on data movement, pointer manipulations and integer arithmetic; more refined retrieval algorithms may in addition benefit from substantial computational power.  In the present study a number of parallel processing methods are described that serve to enhance retrieval services.  In conventional retrieval environments parallel list processing and parallel search facilities are of greatest interest.  In more advanced systems, the use of array processors also proves beneficial.  Various information retrieval processes are examined and evidence is given to demonstrate the usefulness of parallel processing and fast computational facilities in information retrieval.', '102': 'The frequency characteristics of terms in the documents of a collection have been used as indicators of term importance for content analysis and indexing purposes.  In particular, very rare or very frequent terms are normally believed to be less effective than medium-frequency terms.  Recently automatic indexing theories have been devised that use not only the term frequency characteristics but also the relevance properties of the terms. The major term-weighting theories are first briefly reviewed.  The term precision and term utility weights that are based on the occurrence characteristics of the terms in the relevant, as opposed to the nonrelevant, documents of a collection are then introduced.  Methods are suggested for estimating the relevance properties of the terms based on their overall occurrence characteristics in the collection.  Finally, experimental evaluation results are shown comparing the weighting systems using the term relevance properties with the more conventional frequency-based methodologies.', '103': 'This paper describes the design and implementation of an \"electronic filing machine,\" a machine which is capable of storing large numbers of \"unstructured\" documents in such a way a particular document may be easily and quickly retrieved.  A functional distributed architecture permits the implementation of the system in a mixture of hardware and software.', '104': 'This paper tackles the problem of how one might select further search terms, using relevance feedback, given the search terms in the query.  These search terms are extracted from a maximum spanning tree connecting all the terms in the index term vocabulary.  A number of different spanning trees are generated from a variety of association measures.  The retrieval effectiveness for the different spanning trees is shown to be approximately the same.  Effectiveness is measured in terms of precision and recall, and the retrieval tests are done on three different test collections.', '105': 'Indexing quality determines whether the information content of an indexed document is accurately represented.  Indexing effectiveness measures whether an indexed document is correctly retrieved every time it is relevant to a query.  Measurement of these criteria is cumbersome and costly; data base producers therefore prefer inter-indexer consistency as a measure of indexing quality or effectiveness.  The present article assesses the validity of this substitution in various environments.', '106': \"A set of experiments was conducted to determine the suitability of the Colon Classification as a foundation for the automated analysis, representation and retrieval of primary information from the full text of documents.  Primary information is that information embodied in the text of a document, as opposed to secondary information which is generally in such forms as:  an abstract, a table of contents, or an index. Full text databases were created in two subject areas and queries solicited from specialists in each area.  An automated full text indexing system, along with four automated passage retrieval systems, was created to test the various features of the Colon Classification.  Two Boolean-based systems and one simple word occurrence system were created in order to compare the retrieval results against types of systems which are in more common use.  The systems' retrieval performances were measured using recall and precision and the mean expected search length reduction factors. Overall, it was found that the Colon Classification-based systems did not perform significantly better than the other systems.\", '107': 'A study was carried out of the relationship between the vocabulary of user queries and the vocabulary of documents relevant to the queries, and the value of adding to the document description record in a retrieval system keywords from previous queries for which the document had proved useful. Two test databases incorporating user query keywords were implemented at the School of Library and Information Science, University of Western Ontario.  Clustering of the documents via title and user keywords, a statistical analysis of title-user keyword co-occurrences, and retrieval tests were used to examine the effect of the added keywords.  Results showed the impracticality of the procedure in an operational setting, but indicated the value of analyses with sample data in the development and maintenance of keyword dictionaries and thesauri.', '108': \"A technique of online instruction and assistance to bibliographic data base searchers called Individualized Instruction for Data Access (IIDA) is being developed by Drexel University.  IIDA assists searchers by providing feedback based on real-time analysis while searches are being performed. Extensive help facilities which draw on this analysis are available to users.  Much of the project's experimental work, as described elsewhere, is concerned with the process of searching and the behavior of searchers. This paper will largely address itself to the project's computer system, which is being developed by subcontract with the Franklin Institute's Science Information Services.\", '109': 'It is shown that the mapping of a particular area of science, in this case information science, can be done using authors as units of analysis and the cocitations of pairs of authors as the variable that indicates their \"distances\" from each other.  The analysis assumes that the more two authors are cited together, the closer the relationship between them.  The raw data are cocitation counts drawn online from Social Scisearch (Social Sciences Citation Index) over the period 1972-1979.  GThe resulting map shows (1) identifiable author groups (akin to \"schools\") of information science, (2) locations of these groups with respect to each other, (3) the degree of centrality and peripherality of authors within groups, (4) proximities of authors within group and across group boundaries (\"border authors\" who seem to connect various areas of research), and (5) positions of authors with respect to the map\\'s axes, which were arbitrarily set spanning the most divergent groups in order to aid interpretation.  Cocitation analysis of authors offers a new technique that might contribute to the understanding of intellectual structure in the sciences and possibly in other areas to the extent that those areas rely on serial publications.  The technique establishes authors, as well as documents, as an effective unit in analyzing subject specialties.', '110': 'The \"Office of the Future,\" \"Office Technology,\" \"Word Processing,\" \"Electronic Mail,\" \"Electronic Communications,\" \"Convergence,\" \"Information Management.\"  These are all terms included in the current list of buzz words used to describe current activities in the office technology area.  The high level of investment in factories and plants and the ever-increasing fight to improve productivity by automating the dull, routine jobs are usually quoted and compared with the extremely low investment in improving and automating the equally tedious routine jobs in the office environment; the investment in the factory is quoted as being ten times greater per employee than in the office.  This, however, is changing rapidly and investment on a large scale is already taking place in manhy areas as present-day inflation bites hard, forcing many companies and organizations to take a much closer look at their office operations.', '111': 'An automated document clustering procedure is described which does not require the use of an inter-document similarity matrix and which is independent of the order in which the documents are processed.  The procedure makes use of an initial set of clusters which is derived from certain of the terms in the indexing vocabulary used to characterise the documents in the file.  The retrieval effectiveness obtained using the clustered file is compared with that obtained from serial searching and from use of the single-linkage clustering method.', '112': 'A fast algorithm is described for comparing the lists of terms representing documents in automatic classification experiments.  The speed of the procedure arises from the fact that all of the non-zero-valued coefficicents for a given document are identified together, using an inverted file to the terms in the document collection.  The complexity and running time of the algorithm are compared with previously described procedures.'}\n"
     ]
    }
   ],
   "source": [
    "qry_set\n",
    "queries = list(qry_set.values())\n",
    "\n",
    "print(qry_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cost',\n",
       " 'determination',\n",
       " 'cost',\n",
       " 'associated',\n",
       " 'system',\n",
       " 'automated',\n",
       " 'information']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = queries[25]\n",
    "arr2 = []\n",
    "arr2.append(sentence)\n",
    "\n",
    "for i, sentence in enumerate(arr2):\n",
    "\ttokenized= []\n",
    "\ttokenized.append(preprocess(sentence))\n",
    "\tarr2[i] = tokenized\n",
    "    \n",
    "for i in range(0, len(arr2)):\n",
    "    for sentence in arr2[i]:\n",
    "        tokenized= []\n",
    "        tokenized.append(word_tokenize(sentence))\n",
    "        arr2[i] = tokenized\n",
    "        \n",
    "output2 = []\n",
    "for sublist in arr2:\n",
    "    for item in sublist:\n",
    "        output2.append(item)\n",
    "        \n",
    "output3 = []\n",
    "for sublist in output2:\n",
    "    for item in sublist:\n",
    "        output3.append(item) \n",
    "        \n",
    "output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = instance[output3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1485, 1.0),\n",
       " (1479, 0.7419466888868536),\n",
       " (1492, 0.7385927515958791),\n",
       " (590, 0.7310487102056978),\n",
       " (614, 0.7179317410779179),\n",
       " (1474, 0.6981183168205428),\n",
       " (1486, 0.6943263374106541),\n",
       " (1472, 0.691990175981444),\n",
       " (629, 0.6809089506286393),\n",
       " (859, 0.6804631523674107),\n",
       " (1475, 0.6783448809367101),\n",
       " (457, 0.6769243611613541),\n",
       " (1037, 0.6763617538800234),\n",
       " (73, 0.6750355701356824),\n",
       " (537, 0.67411958344848),\n",
       " (335, 0.6738038764918624),\n",
       " (1482, 0.6733461118733812),\n",
       " (638, 0.6711088616982802),\n",
       " (826, 0.6706565676877387),\n",
       " (1138, 0.669632910117367),\n",
       " (489, 0.6682311741063953),\n",
       " (1514, 0.6681227576228898),\n",
       " (1468, 0.6679700028363414),\n",
       " (779, 0.6673708045344651),\n",
       " (66, 0.6665224448972469),\n",
       " (26, 0.6661822111821794),\n",
       " (480, 0.665817917541847),\n",
       " (450, 0.6656242491699056),\n",
       " (1077, 0.6645362385461581),\n",
       " (1142, 0.6617954984015394),\n",
       " (1373, 0.6616908769391502),\n",
       " (1135, 0.6607415778279251),\n",
       " (179, 0.660391240204107),\n",
       " (1281, 0.6602827648366429),\n",
       " (1124, 0.6602054644789969),\n",
       " (493, 0.6586966912558169),\n",
       " (821, 0.6585990547101437),\n",
       " (1546, 0.6565622495029936),\n",
       " (564, 0.6564818463860004),\n",
       " (1464, 0.6564442420812678),\n",
       " (716, 0.6542692474310219),\n",
       " (1360, 0.6542451259063705),\n",
       " (174, 0.6538593465400153),\n",
       " (473, 0.6533630063015589),\n",
       " (458, 0.6531944503135751),\n",
       " (1099, 0.6530727963513522),\n",
       " (127, 0.6530228489808888),\n",
       " (1095, 0.6529945670385426),\n",
       " (1052, 0.6529328233071144),\n",
       " (1540, 0.652670745931044),\n",
       " (1557, 0.6526122047562932),\n",
       " (1522, 0.6525828423000816),\n",
       " (65, 0.6523501844438936),\n",
       " (1120, 0.6521714576424799),\n",
       " (1487, 0.6521371536986162),\n",
       " (573, 0.6518788761693611),\n",
       " (1488, 0.6518121043120688),\n",
       " (533, 0.651745622418296),\n",
       " (1559, 0.651465973933515),\n",
       " (1560, 0.6511025769706265),\n",
       " (522, 0.6509693739424488),\n",
       " (178, 0.6509649362920111),\n",
       " (1515, 0.6502836782504356),\n",
       " (610, 0.6502741432167989),\n",
       " (1100, 0.6502336468896303),\n",
       " (1409, 0.6499213750835481),\n",
       " (1104, 0.6498093428939588),\n",
       " (134, 0.6495188705585571),\n",
       " (1222, 0.6492478504416297),\n",
       " (293, 0.6492374489300982),\n",
       " (688, 0.6487659175668543),\n",
       " (1553, 0.6486063218377669),\n",
       " (616, 0.6484723367008408),\n",
       " (291, 0.6483849777859746),\n",
       " (496, 0.6479758585932662),\n",
       " (647, 0.647072322300928),\n",
       " (1476, 0.6470661391283118),\n",
       " (1359, 0.6470557748488313),\n",
       " (467, 0.646935899531501),\n",
       " (308, 0.6468489432320192),\n",
       " (1491, 0.6467551777138122),\n",
       " (1484, 0.6466364608986557),\n",
       " (1412, 0.6464678291275343),\n",
       " (157, 0.646397449046513),\n",
       " (483, 0.6460899602984194),\n",
       " (871, 0.646074743453429),\n",
       " (525, 0.6459185750523971),\n",
       " (593, 0.6457143923899601),\n",
       " (499, 0.645641163301823),\n",
       " (630, 0.6452366803949683),\n",
       " (1548, 0.6447531356258899),\n",
       " (894, 0.6445814075535579),\n",
       " (689, 0.6445558063218543),\n",
       " (1357, 0.6445314294644917),\n",
       " (578, 0.644496596250292),\n",
       " (531, 0.6444734303606888),\n",
       " (1170, 0.6441626434793503),\n",
       " (527, 0.6441044537580175),\n",
       " (1565, 0.6440555464345081),\n",
       " (1169, 0.644002873270179),\n",
       " (1558, 0.6439305023825255),\n",
       " (500, 0.6439136873148008),\n",
       " (481, 0.6438548403809907),\n",
       " (371, 0.6435841099944584),\n",
       " (508, 0.6434863238385309),\n",
       " (253, 0.6432253716099328),\n",
       " (624, 0.643190060944643),\n",
       " (119, 0.6428374262082087),\n",
       " (1304, 0.6427807320515003),\n",
       " (1542, 0.6426713128378847),\n",
       " (55, 0.6425608339108203),\n",
       " (453, 0.6425392057120082),\n",
       " (646, 0.6423575166759102),\n",
       " (53, 0.6422607942771487),\n",
       " (978, 0.6421897541081723),\n",
       " (778, 0.6420433008491896),\n",
       " (605, 0.641677836549367),\n",
       " (71, 0.6415753717541981),\n",
       " (123, 0.6413737577925442),\n",
       " (592, 0.6411128447616745),\n",
       " (1034, 0.6404762819312071),\n",
       " (882, 0.6401500904669274),\n",
       " (1415, 0.6401463497670146),\n",
       " (594, 0.6398261518457179),\n",
       " (432, 0.639800951689173),\n",
       " (1538, 0.6397682463817471),\n",
       " (1544, 0.639516823593126),\n",
       " (574, 0.6393840422483229),\n",
       " (947, 0.6388824353127158),\n",
       " (641, 0.6388603726041668),\n",
       " (1297, 0.6388448499056653),\n",
       " (1127, 0.6388193138570364),\n",
       " (583, 0.6387872325544028),\n",
       " (841, 0.638753411573982),\n",
       " (444, 0.6385355594177887),\n",
       " (72, 0.6384954047797983),\n",
       " (1366, 0.6382845024081754),\n",
       " (377, 0.638246848010859),\n",
       " (1306, 0.6382344967171122),\n",
       " (290, 0.6379151905117204),\n",
       " (517, 0.6378062748251473),\n",
       " (973, 0.6370858160635527),\n",
       " (924, 0.6370672926914778),\n",
       " (620, 0.6369805110937006),\n",
       " (1133, 0.636920717960306),\n",
       " (839, 0.6368526083999096),\n",
       " (1119, 0.6368154914208022),\n",
       " (896, 0.6367159327307778),\n",
       " (628, 0.6362198538990926),\n",
       " (287, 0.636119052954064),\n",
       " (828, 0.6359825552174356),\n",
       " (113, 0.6357088353106828),\n",
       " (388, 0.6355565170999511),\n",
       " (1121, 0.6355452523231944),\n",
       " (681, 0.6355262866199225),\n",
       " (1126, 0.6353915137268956),\n",
       " (702, 0.6353631258542578),\n",
       " (1404, 0.6353457768448981),\n",
       " (1106, 0.6353073117627528),\n",
       " (1115, 0.6353021960916874),\n",
       " (1374, 0.6350983057412298),\n",
       " (538, 0.6350503405964274),\n",
       " (48, 0.6349952434444881),\n",
       " (1524, 0.6348886360420223),\n",
       " (374, 0.634818413493609),\n",
       " (706, 0.6347296727648852),\n",
       " (1076, 0.6346378501076766),\n",
       " (1012, 0.6346128578077751),\n",
       " (243, 0.6342895515993326),\n",
       " (1504, 0.6342193463902812),\n",
       " (981, 0.634192937577142),\n",
       " (381, 0.6340562053247988),\n",
       " (278, 0.6338365165902113),\n",
       " (164, 0.633526928430065),\n",
       " (524, 0.6334481467097225),\n",
       " (56, 0.6333165709341015),\n",
       " (213, 0.6332964142623309),\n",
       " (1263, 0.6332934731563739),\n",
       " (1111, 0.6331747761388244),\n",
       " (709, 0.6330399052122719),\n",
       " (971, 0.6329752634735953),\n",
       " (1006, 0.632777752911665),\n",
       " (1447, 0.6326398433611946),\n",
       " (571, 0.6325138849925408),\n",
       " (645, 0.6323331290475566),\n",
       " (266, 0.6321230950800292),\n",
       " (375, 0.6319964928730619),\n",
       " (625, 0.6319745679482534),\n",
       " (736, 0.6319428804048757),\n",
       " (669, 0.6319120626014647),\n",
       " (1105, 0.631730542882472),\n",
       " (1136, 0.631700191327692),\n",
       " (864, 0.6316956924093784),\n",
       " (883, 0.6314754680611501),\n",
       " (513, 0.6314213103583619),\n",
       " (1092, 0.6312990649903149),\n",
       " (1125, 0.6312192411991198),\n",
       " (814, 0.6312121820746016),\n",
       " (528, 0.6311945218770761),\n",
       " (1367, 0.6310812662919918),\n",
       " (331, 0.630960735141468),\n",
       " (1529, 0.6307368199956771),\n",
       " (1562, 0.63073434150649),\n",
       " (1102, 0.6306644361217129),\n",
       " (606, 0.6306622236629407),\n",
       " (298, 0.6305914280478354),\n",
       " (320, 0.6305336002313429),\n",
       " (1011, 0.6304637859105142),\n",
       " (301, 0.6304219119306089),\n",
       " (351, 0.6301391678850358),\n",
       " (838, 0.6300263716034532),\n",
       " (1370, 0.6300257171353808),\n",
       " (1363, 0.6298381455243157),\n",
       " (825, 0.6296134888341605),\n",
       " (703, 0.6295368735322194),\n",
       " (552, 0.6293868716424835),\n",
       " (609, 0.62933658919894),\n",
       " (636, 0.6293086674455217),\n",
       " (915, 0.6293012903883253),\n",
       " (362, 0.629193331562397),\n",
       " (1501, 0.629171660711846),\n",
       " (848, 0.6291270902234853),\n",
       " (212, 0.6290983231338747),\n",
       " (1039, 0.6286388008027256),\n",
       " (1541, 0.628584368958536),\n",
       " (249, 0.628462770669632),\n",
       " (738, 0.6282759325857314),\n",
       " (1470, 0.6282311353045743),\n",
       " (133, 0.6282180048233165),\n",
       " (372, 0.6281032788963938),\n",
       " (1080, 0.6280065461480835),\n",
       " (961, 0.6280015298862447),\n",
       " (1192, 0.6279729192157788),\n",
       " (420, 0.6278190681717262),\n",
       " (852, 0.6277725381356697),\n",
       " (633, 0.6275846576375824),\n",
       " (834, 0.6275694288035321),\n",
       " (534, 0.6275291276827835),\n",
       " (584, 0.6275041999963162),\n",
       " (1326, 0.6275008292162934),\n",
       " (539, 0.6274918201709826),\n",
       " (176, 0.6274846469067475),\n",
       " (722, 0.6273820089637584),\n",
       " (1206, 0.6272465005694415),\n",
       " (1112, 0.6270575431980178),\n",
       " (1224, 0.6270537619580837),\n",
       " (221, 0.6270056381618777),\n",
       " (507, 0.626985613085778),\n",
       " (1160, 0.6266189417667312),\n",
       " (954, 0.6265613159910982),\n",
       " (1109, 0.6262405633886542),\n",
       " (125, 0.6261590009640658),\n",
       " (490, 0.6261222970422871),\n",
       " (514, 0.6261159638410004),\n",
       " (644, 0.6260232880031762),\n",
       " (1131, 0.6259955596467001),\n",
       " (1490, 0.6259602911317187),\n",
       " (470, 0.625949078066821),\n",
       " (1282, 0.625711048984953),\n",
       " (992, 0.6255987915663976),\n",
       " (116, 0.6255854817312952),\n",
       " (1520, 0.6255053766805349),\n",
       " (503, 0.6254495706054607),\n",
       " (1466, 0.6253692276068),\n",
       " (77, 0.6253631011953044),\n",
       " (879, 0.6253249388628427),\n",
       " (1481, 0.625207647185489),\n",
       " (1162, 0.6250904687020739),\n",
       " (1556, 0.6250186589534785),\n",
       " (1097, 0.6249330629717247),\n",
       " (207, 0.6249142392932577),\n",
       " (1502, 0.6247401820196461),\n",
       " (1091, 0.6247291446558518),\n",
       " (315, 0.6247244988652196),\n",
       " (1316, 0.6247041182739714),\n",
       " (705, 0.6246488719767495),\n",
       " (1154, 0.6244891691798742),\n",
       " (1235, 0.62448363097903),\n",
       " (643, 0.6244473852280097),\n",
       " (1418, 0.6244353700303176),\n",
       " (452, 0.6244325882388991),\n",
       " (201, 0.6242329303768108),\n",
       " (873, 0.6242295179597459),\n",
       " (309, 0.6242190279038753),\n",
       " (1093, 0.6242173258358849),\n",
       " (770, 0.6242035011465437),\n",
       " (916, 0.624128903536098),\n",
       " (1026, 0.6241245064977282),\n",
       " (84, 0.6236908320886987),\n",
       " (805, 0.6236284751583624),\n",
       " (1554, 0.6235823797181395),\n",
       " (784, 0.6234895792553231),\n",
       " (1129, 0.6234561400940697),\n",
       " (361, 0.6234482591697389),\n",
       " (1547, 0.6233271435518509),\n",
       " (1163, 0.6232611094644196),\n",
       " (1161, 0.6232170601169662),\n",
       " (869, 0.623205435204367),\n",
       " (1137, 0.6231921341309108),\n",
       " (1128, 0.6231549346750325),\n",
       " (433, 0.6230980623149448),\n",
       " (326, 0.6230716660414457),\n",
       " (173, 0.6230548967191198),\n",
       " (622, 0.6229983593343447),\n",
       " (657, 0.6229310004154607),\n",
       " (506, 0.622899163167879),\n",
       " (346, 0.6228583690998856),\n",
       " (1416, 0.622692274063135),\n",
       " (937, 0.62261396338654),\n",
       " (560, 0.6225457149728318),\n",
       " (732, 0.6222951183150253),\n",
       " (545, 0.622251655920926),\n",
       " (741, 0.6221745204025642),\n",
       " (719, 0.6221695984878889),\n",
       " (29, 0.6221066948464031),\n",
       " (324, 0.6220140186194226),\n",
       " (854, 0.6220008637063176),\n",
       " (865, 0.621978757326565),\n",
       " (491, 0.6219636660697364),\n",
       " (955, 0.6219622545939428),\n",
       " (422, 0.6219508417623736),\n",
       " (1507, 0.6218019990517972),\n",
       " (1157, 0.6217097122466323),\n",
       " (407, 0.6216508538701817),\n",
       " (248, 0.6216249024329854),\n",
       " (683, 0.6215188390870725),\n",
       " (632, 0.621477961847305),\n",
       " (1494, 0.6214765438041226),\n",
       " (1021, 0.6214510517227128),\n",
       " (79, 0.6213829338370196),\n",
       " (697, 0.6212700441219412),\n",
       " (808, 0.6212601425821799),\n",
       " (619, 0.6212359045202581),\n",
       " (512, 0.6212255204813916),\n",
       " (1292, 0.6211746288537116),\n",
       " (589, 0.6211717509145737),\n",
       " (1308, 0.621170350973167),\n",
       " (1567, 0.6211108341348648),\n",
       " (1178, 0.6210823510779381),\n",
       " (58, 0.6210599447617933),\n",
       " (190, 0.6210282935188692),\n",
       " (139, 0.6209878518635626),\n",
       " (969, 0.6209877598007509),\n",
       " (82, 0.6209485899655037),\n",
       " (1257, 0.6208970850463961),\n",
       " (800, 0.6208918706698586),\n",
       " (518, 0.620703481466828),\n",
       " (1056, 0.620615256656056),\n",
       " (1517, 0.6205925336518968),\n",
       " (699, 0.6205633156619531),\n",
       " (482, 0.6205407112937708),\n",
       " (1190, 0.6204620690866584),\n",
       " (654, 0.6204077590438549),\n",
       " (280, 0.6203528635139725),\n",
       " (60, 0.6202109489598675),\n",
       " (1510, 0.6200197882269968),\n",
       " (960, 0.6199345366675559),\n",
       " (251, 0.6198960874750827),\n",
       " (653, 0.6198586688927739),\n",
       " (1173, 0.6198319623550029),\n",
       " (983, 0.619806126546548),\n",
       " (670, 0.6195693075209977),\n",
       " (694, 0.6195437304009461),\n",
       " (840, 0.619542132380161),\n",
       " (466, 0.6195181202848551),\n",
       " (319, 0.6194795082439041),\n",
       " (600, 0.6194728852359984),\n",
       " (850, 0.6194014940819647),\n",
       " (345, 0.619399782864468),\n",
       " (121, 0.6193374479711831),\n",
       " (680, 0.6192915544659671),\n",
       " (1364, 0.6192583261696908),\n",
       " (691, 0.6192080664541855),\n",
       " (772, 0.6191874820607266),\n",
       " (349, 0.6191823605949748),\n",
       " (849, 0.6191636389611769),\n",
       " (596, 0.6191129752199539),\n",
       " (1189, 0.6191117206980212),\n",
       " (151, 0.6191091106710387),\n",
       " (494, 0.6190015653733658),\n",
       " (791, 0.6189990904887226),\n",
       " (464, 0.6189862719204289),\n",
       " (1352, 0.618983739420093),\n",
       " (1061, 0.6189563609360075),\n",
       " (497, 0.6189449599486248),\n",
       " (426, 0.6189239730337464),\n",
       " (501, 0.6188174375058616),\n",
       " (1108, 0.6188141712752074),\n",
       " (1050, 0.6187827235566747),\n",
       " (833, 0.6186054744322315),\n",
       " (1113, 0.6184811197029907),\n",
       " (874, 0.6184690872146814),\n",
       " (658, 0.6183698358798472),\n",
       " (316, 0.6183505768135774),\n",
       " (122, 0.6183440496251168),\n",
       " (889, 0.6183275924234664),\n",
       " (982, 0.6183215659102438),\n",
       " (1240, 0.6182727018053285),\n",
       " (1072, 0.6182455085420588),\n",
       " (1420, 0.6182383855605692),\n",
       " (1094, 0.6182223143680999),\n",
       " (145, 0.618203117503248),\n",
       " (425, 0.6181970698634457),\n",
       " (708, 0.6181491599152641),\n",
       " (626, 0.6180856985415732),\n",
       " (1523, 0.6180400373139762),\n",
       " (63, 0.6180105543517086),\n",
       " (28, 0.6179623729140685),\n",
       " (997, 0.6179393802455022),\n",
       " (1505, 0.6179296697196542),\n",
       " (1340, 0.6179229246378991),\n",
       " (427, 0.6179015232519773),\n",
       " (970, 0.6178136324047286),\n",
       " (485, 0.6177328460681852),\n",
       " (611, 0.6176869369161004),\n",
       " (730, 0.6176735473553698),\n",
       " (1289, 0.6176547076437475),\n",
       " (1533, 0.6176389117483528),\n",
       " (1288, 0.6176168621335776),\n",
       " (1518, 0.6175581112435033),\n",
       " (1172, 0.6174473881489158),\n",
       " (906, 0.6173687021880911),\n",
       " (510, 0.6173245493897964),\n",
       " (318, 0.617189209902049),\n",
       " (1153, 0.6170872439785507),\n",
       " (717, 0.6169666174797838),\n",
       " (1219, 0.616964412318672),\n",
       " (120, 0.6169549969101588),\n",
       " (1361, 0.6169112554102909),\n",
       " (640, 0.6168513949289136),\n",
       " (405, 0.6168251046209795),\n",
       " (1365, 0.6167864637515807),\n",
       " (418, 0.6166998003643962),\n",
       " (723, 0.616680301655499),\n",
       " (1555, 0.6164820737889214),\n",
       " (511, 0.6164577335652309),\n",
       " (1152, 0.6163669473894622),\n",
       " (958, 0.6163032304547841),\n",
       " (1493, 0.6162083382115661),\n",
       " (556, 0.6162051397670251),\n",
       " (1098, 0.6161475650517702),\n",
       " (1079, 0.6160955938345707),\n",
       " (851, 0.616024087103657),\n",
       " (1241, 0.6158842404660139),\n",
       " (303, 0.6156351415297784),\n",
       " (1038, 0.6156111694383324),\n",
       " (152, 0.6155550739204939),\n",
       " (1543, 0.6155368197969836),\n",
       " (217, 0.6155355583451128),\n",
       " (988, 0.6155062851518138),\n",
       " (175, 0.6154439069685577),\n",
       " (1294, 0.6153586151456838),\n",
       " (693, 0.6153424996443688),\n",
       " (1509, 0.6152347477922345),\n",
       " (206, 0.6152050603254365),\n",
       " (692, 0.6151127351320663),\n",
       " (1467, 0.6151036255532345),\n",
       " (675, 0.6150891671875418),\n",
       " (1512, 0.615025031920994),\n",
       " (140, 0.6150242052902911),\n",
       " (936, 0.6149992666662072),\n",
       " (445, 0.6149899748073934),\n",
       " (118, 0.6149584511032692),\n",
       " (1469, 0.6149549473655627),\n",
       " (1014, 0.6148908741179238),\n",
       " (946, 0.614877507807176),\n",
       " (1293, 0.6148103804059102),\n",
       " (870, 0.6147933339474665),\n",
       " (581, 0.6147406312565392),\n",
       " (486, 0.6146901745746671),\n",
       " (1478, 0.6146457819602311),\n",
       " (1258, 0.6146054026469584),\n",
       " (1058, 0.614597213388464),\n",
       " (715, 0.6145917193076049),\n",
       " (663, 0.6145872259543852),\n",
       " (797, 0.6145616297140076),\n",
       " (832, 0.6145165469894556),\n",
       " (223, 0.6144845616943471),\n",
       " (1382, 0.6144020435932949),\n",
       " (836, 0.6141884709065778),\n",
       " (474, 0.6141803828693957),\n",
       " (465, 0.6140921356025659),\n",
       " (379, 0.6140893398315157),\n",
       " (15, 0.6140838184899367),\n",
       " (156, 0.6140727620412494),\n",
       " (295, 0.6140263320498566),\n",
       " (673, 0.6140012923495796),\n",
       " (1525, 0.6139405663529823),\n",
       " (136, 0.6139112772877757),\n",
       " (286, 0.613906252986748),\n",
       " (373, 0.6138975395180851),\n",
       " (567, 0.613885576046745),\n",
       " (1508, 0.613776956669076),\n",
       " (305, 0.6137435910190909),\n",
       " (566, 0.6137176788703139),\n",
       " (322, 0.6136977534337676),\n",
       " (460, 0.6136593419738011),\n",
       " (1057, 0.613634904106283),\n",
       " (975, 0.6136291280893158),\n",
       " (1254, 0.6136171073519111),\n",
       " (222, 0.6136090076208269),\n",
       " (1164, 0.6135654952080234),\n",
       " (277, 0.6134956031665793),\n",
       " (431, 0.6134874914373288),\n",
       " (829, 0.6134438327836663),\n",
       " (366, 0.6134037395547536),\n",
       " (1217, 0.6133745641856451),\n",
       " (1358, 0.6133337668140121),\n",
       " (30, 0.6133103809497203),\n",
       " (1406, 0.6132546658061755),\n",
       " (909, 0.6132417725614568),\n",
       " (813, 0.6132250905506553),\n",
       " (1500, 0.6131255682590473),\n",
       " (1291, 0.6130851937776227),\n",
       " (1528, 0.6130323731247475),\n",
       " (447, 0.6129991065072996),\n",
       " (771, 0.6129952445892035),\n",
       " (327, 0.6129645197204808),\n",
       " (1040, 0.6129151389879668),\n",
       " (399, 0.6128985758581683),\n",
       " (844, 0.6128583092482661),\n",
       " (1506, 0.6127535592789377),\n",
       " (1407, 0.6127501501526138),\n",
       " (985, 0.6127362723221994),\n",
       " (1332, 0.6127212105682278),\n",
       " (45, 0.6127024712913731),\n",
       " (76, 0.6126875652212194),\n",
       " (1296, 0.6126804738949129),\n",
       " (495, 0.6126747968803539),\n",
       " (650, 0.6126695190087601),\n",
       " (659, 0.6126496677718261),\n",
       " (461, 0.6126474061570484),\n",
       " (1256, 0.6126209315178731),\n",
       " (698, 0.6126194011601245),\n",
       " (1545, 0.6126182054478511),\n",
       " (244, 0.6125971591727295),\n",
       " (753, 0.6124252204433835),\n",
       " (597, 0.6124043438541272),\n",
       " (294, 0.6123261728829423),\n",
       " (989, 0.6122322827977409),\n",
       " (128, 0.6122292627979237),\n",
       " (423, 0.6122106925589027),\n",
       " (1067, 0.6121895412274052),\n",
       " (1008, 0.6121321958760131),\n",
       " (306, 0.6120525292447204),\n",
       " (421, 0.6119765060313913),\n",
       " (17, 0.6119544507836803),\n",
       " (158, 0.6119419721355502),\n",
       " (1123, 0.6119039796614921),\n",
       " (845, 0.611803095729764),\n",
       " (733, 0.6117381344769215),\n",
       " (990, 0.6116921105545742),\n",
       " (166, 0.6116732379371411),\n",
       " (1223, 0.6115761012645422),\n",
       " (380, 0.611570663662279),\n",
       " (393, 0.6115320268939892),\n",
       " (562, 0.6115122622321734),\n",
       " (1566, 0.6114441834354232),\n",
       " (853, 0.6114319025547668),\n",
       " (357, 0.6113881279943879),\n",
       " (1376, 0.6113671244439635),\n",
       " (1534, 0.6112767575991458),\n",
       " (1511, 0.6110658968764525),\n",
       " (979, 0.6110465260853235),\n",
       " (529, 0.6110110700924816),\n",
       " (1295, 0.6109760117824437),\n",
       " (726, 0.6109675012421897),\n",
       " (163, 0.6109351148468838),\n",
       " (487, 0.6109233635559512),\n",
       " (1143, 0.6108897131316434),\n",
       " (189, 0.6108305457771254),\n",
       " (516, 0.6108091128176137),\n",
       " (337, 0.6107040991174387),\n",
       " (468, 0.6107002508061385),\n",
       " (729, 0.6106420091989178),\n",
       " (1417, 0.6105691370297086),\n",
       " (443, 0.6105686952677952),\n",
       " (1174, 0.6105342039118833),\n",
       " (27, 0.6104769646745922),\n",
       " (1570, 0.610456846381764),\n",
       " (824, 0.6104509483046668),\n",
       " (878, 0.6104034068962307),\n",
       " (1378, 0.6103621901320527),\n",
       " (720, 0.610343652578895),\n",
       " (226, 0.6103350671389485),\n",
       " (509, 0.6102913251346931),\n",
       " (424, 0.6102330646373603),\n",
       " (817, 0.6101967162939849),\n",
       " (1053, 0.6101697659196346),\n",
       " (1233, 0.6101385542157937),\n",
       " (81, 0.6101067132432473),\n",
       " (530, 0.6100682365208676),\n",
       " (795, 0.6100093820729758),\n",
       " (233, 0.609954850465055),\n",
       " (459, 0.6099085437258607),\n",
       " (285, 0.6099036081196677),\n",
       " (1182, 0.6098425007513972),\n",
       " (1381, 0.6097464436385129),\n",
       " (1439, 0.6097316595081821),\n",
       " (3, 0.6097221647176861),\n",
       " (14, 0.609722116079685),\n",
       " (273, 0.6097162378986952),\n",
       " (1047, 0.6097158117176491),\n",
       " (727, 0.6096958110047785),\n",
       " (1088, 0.6096596161259707),\n",
       " (1228, 0.6096595843425662),\n",
       " (855, 0.6096404947738673),\n",
       " (801, 0.6096231640495454),\n",
       " (967, 0.6095251009176278),\n",
       " (796, 0.6095229325974357),\n",
       " (1179, 0.6095032845182601),\n",
       " (1389, 0.6094497881687465),\n",
       " (296, 0.6093458493774505),\n",
       " (205, 0.6093403643218734),\n",
       " (996, 0.6093286784836959),\n",
       " (1390, 0.6093195169648558),\n",
       " (1211, 0.6093183230204534),\n",
       " (607, 0.6092772443991352),\n",
       " (822, 0.6091973624213517),\n",
       " (451, 0.6091538007170325),\n",
       " (1177, 0.6091142997347547),\n",
       " (782, 0.6091089231791919),\n",
       " (1400, 0.6090900893296385),\n",
       " (515, 0.6090900131525671),\n",
       " (347, 0.609087657751197),\n",
       " (1403, 0.6090567128879539),\n",
       " (1535, 0.6090514571581173),\n",
       " (679, 0.6090154311837216),\n",
       " (240, 0.6090131120581324),\n",
       " (1, 0.6089757871702266),\n",
       " (150, 0.6089716986802535),\n",
       " (1408, 0.6088555860285477),\n",
       " (1041, 0.6088280411760923),\n",
       " (10, 0.6087825602841234),\n",
       " (1355, 0.6087041659411893),\n",
       " (1462, 0.6085899543369497),\n",
       " (33, 0.6085860496128088),\n",
       " (265, 0.6085860114908755),\n",
       " (1043, 0.6085231503082648),\n",
       " (1188, 0.6084504788935479),\n",
       " (761, 0.6084349606718091),\n",
       " (1498, 0.6083083994422942),\n",
       " (1461, 0.6082812327033829),\n",
       " (74, 0.6082565301418675),\n",
       " (794, 0.6081439683792564),\n",
       " (364, 0.6080954827923108),\n",
       " (1010, 0.6079795888726094),\n",
       " (598, 0.6079794297176081),\n",
       " (1372, 0.6079458022578959),\n",
       " (177, 0.607905932790546),\n",
       " (881, 0.6078887761752629),\n",
       " (159, 0.6078846873353452),\n",
       " (1036, 0.6078189251698692),\n",
       " (696, 0.6078028039698213),\n",
       " (1521, 0.6077840197732156),\n",
       " (384, 0.6077752363152991),\n",
       " (760, 0.6077451288258576),\n",
       " (1279, 0.6077045353323669),\n",
       " (686, 0.6077004533482739),\n",
       " (1397, 0.6076896493583155),\n",
       " (1110, 0.6076073959765219),\n",
       " (570, 0.6075488940286904),\n",
       " (1353, 0.607538003001174),\n",
       " (553, 0.6074881433802027),\n",
       " (1168, 0.6073593756474336),\n",
       " (965, 0.6073465905008678),\n",
       " (1207, 0.6073439743002348),\n",
       " (519, 0.6073258733962562),\n",
       " (387, 0.6073078033610263),\n",
       " (546, 0.6072254661359716),\n",
       " (144, 0.6072252105218521),\n",
       " (1564, 0.6072100880841962),\n",
       " (1429, 0.6072037555910927),\n",
       " (363, 0.6071981751660889),\n",
       " (1375, 0.6071229721362162),\n",
       " (146, 0.6071104664887912),\n",
       " (1155, 0.6070735098532002),\n",
       " (941, 0.6070563503561325),\n",
       " (155, 0.6070344448339154),\n",
       " (62, 0.607019539193152),\n",
       " (1078, 0.6070149599877297),\n",
       " (816, 0.606961040356877),\n",
       " (1071, 0.6069539722075273),\n",
       " (1426, 0.606926909221185),\n",
       " (1200, 0.6069104767291528),\n",
       " (1229, 0.6068777486987533),\n",
       " (1411, 0.6067982855243091),\n",
       " (1552, 0.6067689622566922),\n",
       " (398, 0.6067557984743333),\n",
       " (1185, 0.6066603600871826),\n",
       " (61, 0.6066478996435478),\n",
       " (57, 0.6066143290417363),\n",
       " (135, 0.606575732849536),\n",
       " (1116, 0.606531551944768),\n",
       " (884, 0.6064387159440566),\n",
       " (130, 0.606400750570215),\n",
       " (230, 0.6063755187925346),\n",
       " (448, 0.6063604123258288),\n",
       " (863, 0.6062511318532263),\n",
       " (1448, 0.606147599619727),\n",
       " (449, 0.6061069637038902),\n",
       " (1165, 0.6060444880798398),\n",
       " (742, 0.60598394788179),\n",
       " (264, 0.6059131339340933),\n",
       " (1075, 0.6058355317022489),\n",
       " (1015, 0.6057103388622799),\n",
       " (227, 0.6057049490826611),\n",
       " (416, 0.605648389095893),\n",
       " (711, 0.605627138557684),\n",
       " (886, 0.6055291658236508),\n",
       " (1253, 0.6055194675713793),\n",
       " (1287, 0.6054936476976932),\n",
       " (1519, 0.6054914975230976),\n",
       " (968, 0.6054158431216314),\n",
       " (1103, 0.6053746682032355),\n",
       " (1499, 0.6053518924090813),\n",
       " (242, 0.6053342180388444),\n",
       " (42, 0.605327615169549),\n",
       " (623, 0.6053048703144422),\n",
       " (1395, 0.6051645526090471),\n",
       " (959, 0.6051617290461714),\n",
       " (1497, 0.6050338316282389),\n",
       " (22, 0.6049574586528108),\n",
       " (1114, 0.6049396219525727),\n",
       " (899, 0.6049372694315965),\n",
       " (191, 0.6049346093257084),\n",
       " (114, 0.6048381848308204),\n",
       " (664, 0.604782472023304),\n",
       " (1317, 0.6046576924349553),\n",
       " (1551, 0.6046346760709663),\n",
       " (1569, 0.60455210601936),\n",
       " (682, 0.6045180249181679),\n",
       " (1183, 0.6044723848204832),\n",
       " (701, 0.6044581240406628),\n",
       " (1302, 0.6043663783138791),\n",
       " (935, 0.6043496078316442),\n",
       " (438, 0.6043042633356462),\n",
       " (1530, 0.6043009445842348),\n",
       " (541, 0.6042976100025229),\n",
       " (940, 0.6042959920491056),\n",
       " (1048, 0.6042607937034862),\n",
       " (678, 0.604247543937806),\n",
       " (1202, 0.6042456949842324),\n",
       " (956, 0.6040959651490385),\n",
       " (1322, 0.6040307266556363),\n",
       " (142, 0.604017766281165),\n",
       " (823, 0.6039864351739277),\n",
       " (68, 0.603934236621445),\n",
       " (535, 0.6038625785945613),\n",
       " (627, 0.6038074167828339),\n",
       " (210, 0.6037918364016968),\n",
       " (898, 0.6037803718059492),\n",
       " (1537, 0.603763525305533),\n",
       " (1445, 0.6036934732295072),\n",
       " (11, 0.6036772228507047),\n",
       " (385, 0.6036671622751331),\n",
       " (842, 0.603659166515387),\n",
       " (1243, 0.6036547184491791),\n",
       " (1396, 0.6036070562984739),\n",
       " (196, 0.6035322751198836),\n",
       " (1266, 0.6034881573004963),\n",
       " (1064, 0.6034855846958636),\n",
       " (41, 0.6034235761828258),\n",
       " (1247, 0.6033952282402129),\n",
       " (434, 0.6033656554205092),\n",
       " (962, 0.6033381161555096),\n",
       " (292, 0.6033349748992405),\n",
       " (966, 0.6033155270574875),\n",
       " (2, 0.603288584420624),\n",
       " (348, 0.6032202425701082),\n",
       " (476, 0.6031890840579629),\n",
       " (804, 0.6031541795242222),\n",
       " (1457, 0.6031455259507179),\n",
       " (247, 0.6031246156862247),\n",
       " (204, 0.6031017561890755),\n",
       " (913, 0.6029922200000856),\n",
       " (1371, 0.602984124990885),\n",
       " (651, 0.602979715063968),\n",
       " (269, 0.6029595954057511),\n",
       " (1356, 0.6029479465877922),\n",
       " (768, 0.6028909173375737),\n",
       " (304, 0.602877374940108),\n",
       " (1208, 0.6028678505078358),\n",
       " (751, 0.6028553348952791),\n",
       " (1527, 0.602837738608745),\n",
       " (1532, 0.602795483390003),\n",
       " (396, 0.6027708994797514),\n",
       " (330, 0.6027036376425825),\n",
       " (228, 0.6025886779527009),\n",
       " (1444, 0.6025881205540328),\n",
       " (1480, 0.6025159220517525),\n",
       " (340, 0.6025119949172217),\n",
       " (16, 0.6024229955891635),\n",
       " (710, 0.6023992453521683),\n",
       " (317, 0.602383293693451),\n",
       " (472, 0.6022599599787963),\n",
       " (1350, 0.6022400514801503),\n",
       " (395, 0.6021337703266163),\n",
       " (1150, 0.6020694167849713),\n",
       " (1351, 0.602033193592803),\n",
       " (428, 0.6020085968034087),\n",
       " (1398, 0.6019968714439281),\n",
       " (731, 0.6018916108722098),\n",
       " (147, 0.6018613646055786),\n",
       " (888, 0.6018583337438101),\n",
       " (336, 0.6018576638275912),\n",
       " (861, 0.601816172334437),\n",
       " (586, 0.6017998918113925),\n",
       " (559, 0.6017927905705511),\n",
       " (101, 0.6017675525042238),\n",
       " (1196, 0.6017578530648848),\n",
       " (1213, 0.6017254735794855),\n",
       " (359, 0.6017146974812805),\n",
       " (440, 0.6015906575232038),\n",
       " (131, 0.6015840492500395),\n",
       " (323, 0.6015591908152005),\n",
       " (1101, 0.601435532721014),\n",
       " (1327, 0.6014187017605734),\n",
       " (1148, 0.6013873268151021),\n",
       " (951, 0.601348935135783),\n",
       " (618, 0.6013474033126192),\n",
       " (367, 0.6013354732856988),\n",
       " (880, 0.6013054629991759),\n",
       " (665, 0.6013040500341527),\n",
       " (417, 0.6012855443288722),\n",
       " (88, 0.6012564358454585),\n",
       " (1246, 0.6011223919715466),\n",
       " (1303, 0.6011183410605335),\n",
       " (1318, 0.6009354261588198),\n",
       " (492, 0.6009215788541269),\n",
       " (735, 0.6009071522682408),\n",
       " (707, 0.6008736471824552),\n",
       " (1571, 0.6008670936285927),\n",
       " (67, 0.6008566653139298),\n",
       " (1449, 0.6007907299801669),\n",
       " (1013, 0.6007774152392665),\n",
       " (1066, 0.6007773517836149),\n",
       " (6, 0.6007442596406859),\n",
       " (639, 0.6007415033490998),\n",
       " (369, 0.6006901990619198),\n",
       " (846, 0.6006844286523435),\n",
       " (1194, 0.6006727915000157),\n",
       " (231, 0.6006607444321113),\n",
       " (1201, 0.6006231476895485),\n",
       " (591, 0.6005511626082611),\n",
       " (660, 0.6005504405123441),\n",
       " (389, 0.600531727467271),\n",
       " (1141, 0.6005252780544911),\n",
       " (1210, 0.600524386488228),\n",
       " (1042, 0.6004696598864175),\n",
       " (806, 0.6003650912914549),\n",
       " (577, 0.60034720095616),\n",
       " (798, 0.6003459078800075),\n",
       " (1073, 0.6003351796466433),\n",
       " (1262, 0.6003144565436289),\n",
       " (1255, 0.6002786361232205),\n",
       " (910, 0.6002164195175916),\n",
       " (1203, 0.6001952535866424),\n",
       " (281, 0.6001407719116871),\n",
       " (521, 0.6001390420372484),\n",
       " (9, 0.600104166176808),\n",
       " (1252, 0.600082402334608),\n",
       " (1273, 0.6000175984253978),\n",
       " (1059, 0.5999536803874924),\n",
       " (536, 0.59990793601006),\n",
       " (599, 0.5998690009518775),\n",
       " (827, 0.5998219043260574),\n",
       " (555, 0.5997806259644642),\n",
       " (368, 0.5997477109235471),\n",
       " (1068, 0.5997371568308697),\n",
       " (31, 0.5997337531366708),\n",
       " (1347, 0.5997197174578105),\n",
       " (980, 0.5997113060640026),\n",
       " (18, 0.5996638786864436),\n",
       " (199, 0.599647093648979),\n",
       " (338, 0.59964222926857),\n",
       " (1023, 0.5995619698723167),\n",
       " (595, 0.5995367618404448),\n",
       " (580, 0.5995336583885149),\n",
       " (718, 0.5994946974187694),\n",
       " (1069, 0.599463492078215),\n",
       " (165, 0.5994483209156193),\n",
       " (695, 0.5994222755194689),\n",
       " (1187, 0.5993991472280041),\n",
       " (24, 0.5993544485462327),\n",
       " (1387, 0.5993540509730155),\n",
       " (1425, 0.5993535462822889),\n",
       " (5, 0.5993234203221012),\n",
       " (608, 0.5993066666865491),\n",
       " (469, 0.5992978512080438),\n",
       " (1531, 0.5992899002363795),\n",
       " (799, 0.5992594651818303),\n",
       " (488, 0.5992532307190701),\n",
       " (1145, 0.5992409336038363),\n",
       " (655, 0.5992093484525185),\n",
       " (505, 0.5991479199732564),\n",
       " (785, 0.5991150103392773),\n",
       " (1312, 0.5990607153299627),\n",
       " (1180, 0.5990592730684068),\n",
       " (143, 0.5990174516160583),\n",
       " (310, 0.5990063085571108),\n",
       " (713, 0.5989718717924425),\n",
       " (759, 0.5989091315426327),\n",
       " (329, 0.5988893471670753),\n",
       " (1225, 0.5988892637836498),\n",
       " (847, 0.5988851827287294),\n",
       " (1384, 0.5988697227454887),\n",
       " (1463, 0.5988471003673006),\n",
       " (216, 0.5988383532935252),\n",
       " (95, 0.5988139015401348),\n",
       " (939, 0.5988103533922787),\n",
       " (802, 0.5987821736589511),\n",
       " (272, 0.598737768203854),\n",
       " (1220, 0.5987142098782235),\n",
       " (1320, 0.5986878606536277),\n",
       " (411, 0.598641545066327),\n",
       " (1430, 0.5986351107337834),\n",
       " (1435, 0.5986244291601647),\n",
       " (1405, 0.5986240314382315),\n",
       " (1362, 0.5986099975181525),\n",
       " (921, 0.598571902930507),\n",
       " (162, 0.598570263610737),\n",
       " (789, 0.598563250619839),\n",
       " (311, 0.5985472607784108),\n",
       " (1536, 0.5983670378894659),\n",
       " (408, 0.5983628864680413),\n",
       " (602, 0.5983542892104782),\n",
       " (938, 0.5983496128375404),\n",
       " (887, 0.5983460379408354),\n",
       " (38, 0.5983065863776975),\n",
       " (167, 0.5982996455134989),\n",
       " (1421, 0.5981653439850453),\n",
       " (1325, 0.5981495519912781),\n",
       " (885, 0.5981367121739593),\n",
       " (1549, 0.598105423433286),\n",
       " (543, 0.5980813276941692),\n",
       " (810, 0.5980507536594137),\n",
       " (137, 0.5980240464882668),\n",
       " (441, 0.5979738966420616),\n",
       " (532, 0.5979051324046936),\n",
       " (478, 0.5979028132044156),\n",
       " (1432, 0.5978969778711003),\n",
       " (70, 0.5978935578324006),\n",
       " (754, 0.5978910502410149),\n",
       " (80, 0.5978631838452575),\n",
       " (891, 0.5978586423212038),\n",
       " (23, 0.5978530545578582),\n",
       " (957, 0.5978503571325432),\n",
       " (739, 0.5978209399212765),\n",
       " (477, 0.5977065125910893),\n",
       " (674, 0.5976479661147094),\n",
       " (907, 0.5976348077264307),\n",
       " (215, 0.5976095086128844),\n",
       " (356, 0.59759211185215),\n",
       " (394, 0.5975895165985148),\n",
       " (568, 0.5975895146745047),\n",
       " (276, 0.5975564263117187),\n",
       " (160, 0.5975115029936919),\n",
       " (1144, 0.5975021661803912),\n",
       " (8, 0.5974606697181243),\n",
       " (279, 0.5974298841674991),\n",
       " (1328, 0.5972688158570556),\n",
       " (1184, 0.5972112351791304),\n",
       " (949, 0.5971404416533103),\n",
       " (725, 0.5971400775999807),\n",
       " (866, 0.597031404654195),\n",
       " (945, 0.5969660472063404),\n",
       " (668, 0.5969489084712846),\n",
       " (615, 0.5968903015271436),\n",
       " (1117, 0.5968900847947873),\n",
       " (963, 0.5968778787565532),\n",
       " (563, 0.596795902019497),\n",
       " (1044, 0.5967545725451695),\n",
       " (328, 0.5967517416418333),\n",
       " (565, 0.5967459256848762),\n",
       " (124, 0.5966785720123828),\n",
       " (1232, 0.5966550327206754),\n",
       " (1132, 0.5966093662359961),\n",
       " (1369, 0.5965968061354683),\n",
       " (897, 0.5965582344904148),\n",
       " (677, 0.5965518726852816),\n",
       " (750, 0.5965497486043804),\n",
       " (1451, 0.5965457537583297),\n",
       " (575, 0.5965113607992308),\n",
       " (1147, 0.5964727881976029),\n",
       " (642, 0.5964503241551782),\n",
       " (1197, 0.5964292637863849),\n",
       " (1465, 0.5963957055721802),\n",
       " (991, 0.5963846056013976),\n",
       " (1436, 0.5963624426078747),\n",
       " (569, 0.5962538036881981),\n",
       " (944, 0.5962443041480278),\n",
       " (1410, 0.5962440140992549),\n",
       " (1455, 0.5962109204234465),\n",
       " (920, 0.5961996873707135),\n",
       " (390, 0.5961862988737945),\n",
       " (1324, 0.5961730518602004),\n",
       " (1561, 0.5961502395476611),\n",
       " (313, 0.5961379416818058),\n",
       " (867, 0.5961116503522178),\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=[]\n",
    "for i in range(0,260):\n",
    "    if(sims[i][0] < 1460):\n",
    "        res.append(sims[i][0] +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 27, 36, 67, 74, 83, 126, 158, 164, 192, 214, 218, 307, 338, 364, 365, 372, 381, 446, 458, 465, 468, 474, 490, 491, 495, 496, 497, 500, 507, 523, 534, 584, 591, 615, 620, 639, 675, 690, 723, 732, 779, 813, 822, 848, 849, 860, 865, 979, 1100, 1264, 1366, 1368, 1374, 1376, 1377]\n"
     ]
    }
   ],
   "source": [
    "rel1=[]\n",
    "rel1= rel_set[\"26\"]\n",
    "for i in range(0, len(rel1)): \n",
    "    rel1[i] = int(rel1[i])\n",
    "    \n",
    "print(rel1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = len(intersection(res, rel1))\n",
    "y = len(rel1)\n",
    "z = len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.14285714285714"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = x/y * 100\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.414414414414415"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = x/z * 100\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.021582733812952"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = 2*(P*R)/(P+R)\n",
    "F"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
